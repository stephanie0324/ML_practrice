## Seq2Seq Tasks
### ML2023-HW5-Translation
model here :point_right: : [link]()
1. In strong basleine (can't log in to JudgeBoi)
2. TODOs
   * Train a simple RNN seq2seq to acheive translation -> add layers and more epochs
   * Switch to transformer model to boost performance -> change to transformer encoder and decoder
   * Apply Back-translation to furthur boost performance (pass)
