## Seq2Seq Tasks
### ML2023-HW5-Translation
model here :point_right: : [link](https://github.com/stephanie0324/ML_practrice/blob/master/Seq2Seq/ML2023-HW5-Translation.ipynb)
1. In strong basleine (can't log in to JudgeBoi)
2. TODOs
   * Train a simple RNN seq2seq to acheive translation -> add layers and more epochs
   * Switch to transformer model to boost performance -> change to transformer encoder and decoder
   * Apply Back-translation to furthur boost performance (pass)
